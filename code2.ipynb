{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "580abacc-cc65-4d59-a313-56ac035cd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms  # 使用v1版本\n",
    "import torchvision.io as tv_io\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412a5928-e80b-48f2-8bff-f84d5debbb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61995a7b-8cc4-41c0-b80b-6e338b464557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "weights = VGG16_Weights.DEFAULT\n",
    "vgg_model = vgg16(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a422ef0-5b15-42dd-8a07-1e3fd7a2d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结基础模型的参数\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39705a84-03e8-4317-bbe4-31ebf63d4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 7\n",
    "\n",
    "my_model = nn.Sequential(\n",
    "    vgg_model.features,\n",
    "    vgg_model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    vgg_model.classifier[0:3],\n",
    "    nn.Linear(4096, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, N_CLASSES)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783ce0e4-bafe-4138-bf81-f00c75e61e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(my_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a003a8fe-4d80-4228-a519-20727ce3d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率调度器\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ee7238-c6a8-4721-86db-485a3455e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强与预处理\n",
    "IMG_WIDTH, IMG_HEIGHT = (224, 224)\n",
    "random_trans = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(IMG_HEIGHT, IMG_WIDTH), scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9c5a0e-57da-4e80-b4a6-c95cf1f489c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LABELS = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        for l_idx, label in enumerate(DATA_LABELS):\n",
    "            data_paths = glob.glob(data_dir + label + '/*.jpg', recursive=True)\n",
    "            for path in data_paths:\n",
    "                # 使用 PIL.Image 打开图像并进行转换\n",
    "                img = Image.open(path).convert('RGB')\n",
    "                img = random_trans(img)  # 应用数据增强变换\n",
    "                self.imgs.append(img.to(device))\n",
    "                self.labels.append(torch.tensor(l_idx).to(device))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b76dba-4fe5-491b-b790-e318d0901923",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "train_path = \"picture/train/\"\n",
    "train_data = MyDataset(train_path)\n",
    "train_loader = DataLoader(train_data, batch_size=n, shuffle=True)\n",
    "\n",
    "valid_path = \"picture/val/\"\n",
    "valid_data = MyDataset(valid_path)\n",
    "valid_loader = DataLoader(valid_data, batch_size=n, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7571f859-9cda-4d61-baef-0845bbabe197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c45ca47-11f3-456b-a519-ada53bb9cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf6e081-0bb3-4a1d-9b0e-812907fe0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    loss_total = 0.0\n",
    "\n",
    "    with torch.no_grad():  # 在验证时不计算梯度\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = loss_function(output, y)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "            # 获取预测结果\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = loss_total / len(valid_loader)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_labels)).mean()\n",
    "\n",
    "    # 计算精确率和召回率\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    # 计算均方误差 (MSE) 和平均绝对误差 (MAE)\n",
    "    mse = mean_squared_error(all_labels, all_predictions)\n",
    "    mae = mean_absolute_error(all_labels, all_predictions)\n",
    "\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MSE: {mse:.4f}, MAE: {mae:.4f}')\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15efad36-f841-4942-8254-695655b4b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 1.0629\n",
      "Validation Loss: 1.3371, Accuracy: 0.5052, Precision: 0.5037, Recall: 0.5052, MSE: 4.0912, MAE: 1.2449\n",
      "Epoch: 1\n",
      "Train Loss: 1.0507\n",
      "Validation Loss: 1.3455, Accuracy: 0.5043, Precision: 0.4954, Recall: 0.5043, MSE: 4.2672, MAE: 1.2764\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 2\n",
      "Train Loss: 1.0434\n",
      "Validation Loss: 1.3491, Accuracy: 0.5077, Precision: 0.5022, Recall: 0.5077, MSE: 4.1013, MAE: 1.2416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch: 3\n",
      "Train Loss: 1.0387\n",
      "Validation Loss: 1.3573, Accuracy: 0.5040, Precision: 0.4967, Recall: 0.5040, MSE: 4.0971, MAE: 1.2413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch: 4\n",
      "Train Loss: 1.0256\n",
      "Validation Loss: 1.3711, Accuracy: 0.5040, Precision: 0.5075, Recall: 0.5040, MSE: 4.1933, MAE: 1.2605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch: 5\n",
      "Train Loss: 1.0146\n",
      "Validation Loss: 1.3528, Accuracy: 0.5149, Precision: 0.5120, Recall: 0.5149, MSE: 4.0589, MAE: 1.2271\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 6\n",
      "Train Loss: 1.0143\n",
      "Validation Loss: 1.3591, Accuracy: 0.5052, Precision: 0.5023, Recall: 0.5052, MSE: 4.2421, MAE: 1.2630\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 7\n",
      "Train Loss: 1.0031\n",
      "Validation Loss: 1.3736, Accuracy: 0.5043, Precision: 0.4934, Recall: 0.5043, MSE: 4.2326, MAE: 1.2614\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 8\n",
      "Train Loss: 0.9918\n",
      "Validation Loss: 1.3961, Accuracy: 0.5066, Precision: 0.4977, Recall: 0.5066, MSE: 3.9933, MAE: 1.2251\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 9\n",
      "Train Loss: 0.9867\n",
      "Validation Loss: 1.3647, Accuracy: 0.5177, Precision: 0.5082, Recall: 0.5177, MSE: 3.8502, MAE: 1.1941\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.9813\n",
      "Validation Loss: 1.3525, Accuracy: 0.5060, Precision: 0.5035, Recall: 0.5060, MSE: 4.3208, MAE: 1.2798\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    train_loss = train(my_model, train_loader, loss_function)\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    \n",
    "    val_loss = validate(my_model, valid_loader)\n",
    "    \n",
    "    early_stopping(val_loss)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6d14cce-cc73-4f08-8019-1e3ba7b4f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解冻基础模型进行微调\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = Adam(my_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6952aa0-e812-4dad-af98-c4ab0657d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1081, Accuracy: 0.5760, Precision: 0.5817, Recall: 0.5760, MSE: 3.6577, MAE: 1.0904\n",
      "Fine-tuning Epoch: 1\n",
      "Validation Loss: 1.0456, Accuracy: 0.5997, Precision: 0.6201, Recall: 0.5997, MSE: 3.7874, MAE: 1.0817\n",
      "Fine-tuning Epoch: 2\n",
      "Validation Loss: 1.0047, Accuracy: 0.6223, Precision: 0.6382, Recall: 0.6223, MSE: 3.4622, MAE: 1.0064\n",
      "Fine-tuning Epoch: 3\n",
      "Validation Loss: 0.9780, Accuracy: 0.6477, Precision: 0.6416, Recall: 0.6477, MSE: 2.8756, MAE: 0.8812\n",
      "Fine-tuning Epoch: 4\n",
      "Validation Loss: 1.1355, Accuracy: 0.6435, Precision: 0.6424, Recall: 0.6435, MSE: 3.0142, MAE: 0.9082\n",
      "Fine-tuning Epoch: 5\n",
      "Validation Loss: 1.2182, Accuracy: 0.6296, Precision: 0.6411, Recall: 0.6296, MSE: 3.3414, MAE: 0.9788\n",
      "Fine-tuning Epoch: 6\n",
      "Validation Loss: 1.3633, Accuracy: 0.6374, Precision: 0.6502, Recall: 0.6374, MSE: 3.1174, MAE: 0.9339\n",
      "Fine-tuning Epoch: 7\n",
      "Validation Loss: 1.4708, Accuracy: 0.6432, Precision: 0.6449, Recall: 0.6432, MSE: 2.9654, MAE: 0.9018\n",
      "Fine-tuning Epoch: 8\n",
      "Validation Loss: 1.6606, Accuracy: 0.6391, Precision: 0.6394, Recall: 0.6391, MSE: 3.0368, MAE: 0.9197\n",
      "Fine-tuning Epoch: 9\n",
      "Validation Loss: 1.7625, Accuracy: 0.6410, Precision: 0.6389, Recall: 0.6410, MSE: 3.0259, MAE: 0.9121\n"
     ]
    }
   ],
   "source": [
    "# 微调训练过程\n",
    "for epoch in range(10): \n",
    "    print('Fine-tuning Epoch: {}'.format(epoch))\n",
    "    \n",
    "    train(my_model, train_loader, loss_function)\n",
    "    \n",
    "    validate(my_model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9620bc4-2a95-474a-aa37-5709e017b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在验证的图像: picture/test/neutral/3656.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 0.1967\n",
      "disgust: 0.0034\n",
      "fear: 0.0481\n",
      "happy: 0.0002\n",
      "neutral: 0.6114\n",
      "sad: 0.1401\n",
      "surprise: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义数据预处理步骤\n",
    "def load_and_preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.ToTensor(),  # 转换为张量\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')  # 打开图像并转换为RGB格式\n",
    "    image_tensor = transform(image).unsqueeze(0)  # 添加批次维度\n",
    "    return image_tensor.to(device), image  # 返回张量和原始图像\n",
    "\n",
    "# 从test文件夹中随机选择一张图片进行验证\n",
    "def test_random_image(model, test_dir):\n",
    "    all_images = []\n",
    "    \n",
    "    # 收集所有类别的图像路径\n",
    "    for label in DATA_LABELS:\n",
    "        label_dir = os.path.join(test_dir, label)\n",
    "        if os.path.exists(label_dir):\n",
    "            all_images.extend(glob.glob(os.path.join(label_dir, '*.jpg')))  # 假设图像为jpg格式\n",
    "\n",
    "    if not all_images:\n",
    "        print(\"没有找到测试图像！\")\n",
    "        return\n",
    "    \n",
    "    random_image_path = random.choice(all_images)  # 随机选择一张图像\n",
    "    print(f\"正在验证的图像: {random_image_path}\")\n",
    "\n",
    "    image_tensor, original_image = load_and_preprocess_image(random_image_path)  # 加载和预处理图像\n",
    "\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # 获取模型输出\n",
    "        probabilities = torch.softmax(output, dim=1)  # 获取每个类别的概率\n",
    "        prediction_idx = output.argmax(dim=1).item()  # 获取预测类别索引\n",
    "\n",
    "    # 显示原始图像和预测结果\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis('off')  # 不显示坐标轴\n",
    "    plt.title(f\"prediction: {DATA_LABELS[prediction_idx]}\")\n",
    "    plt.show()\n",
    "\n",
    "    # 输出每个标签的概率\n",
    "    for i, label in enumerate(DATA_LABELS):\n",
    "        print(f\"{label}: {probabilities[0][i].item():.4f}\")  # 输出格式化的概率值\n",
    "\n",
    "# 调用函数进行验证，指定测试目录路径\n",
    "test_directory = \"picture/test/\"  # 测试图像所在目录\n",
    "test_random_image(my_model, test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48988b-5e86-48ab-891c-678e381d9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
